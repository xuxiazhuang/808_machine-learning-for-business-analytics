{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('shape is', np.shape(digits.data))\n",
    "digits.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9962880475129918"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "logisticRegr.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'image with lavel0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(digits.images[20])\n",
    "plt.title('image with lavel' + str(digits.target[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 9, ..., 7, 7, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [8],\n",
       "       [9],\n",
       "       ...,\n",
       "       [7],\n",
       "       [7],\n",
       "       [8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Expand the shape of an array.\n",
    "np.expand_dims(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare data for tensorflow multi labels\n",
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()#Encode categorical integer features as a one-hot numeric array.\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(np.expand_dims(y_train, axis=1))\n",
    "onehot_train = enc.transform(np.expand_dims(y_train,axis =1)).toarray()### toarray make it good for eyes\n",
    "onehot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## placeholder: Inserts a placeholder for a tensor that will be always fed.\n",
    "X  = tf.placeholder(tf.float32,[None,64])\n",
    "Y_true = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#### define every layers\n",
    "L =200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "### set bias as zero just because this is just initial value\n",
    "w1 = tf.Variable(tf.truncated_normal([64,L],stddev = 0.1)) ## from input layer to first layer\n",
    "b1 = tf.Variable(tf.zeros(L))\n",
    "w2 = tf.Variable(tf.truncated_normal([L,M],stddev = 0.1))\n",
    "b2 = tf.Variable(tf.zeros(M))\n",
    "w3 = tf.Variable(tf.truncated_normal([M,N],stddev = 0.1))\n",
    "b3 = tf.Variable(tf.zeros(N))\n",
    "w4 = tf.Variable(tf.truncated_normal([N,O],stddev = 0.1))\n",
    "b4 = tf.Variable(tf.zeros(O))\n",
    "\n",
    "w5 = tf.Variable(tf.truncated_normal([O,10],stddev = 0.1))\n",
    "b5 = tf.Variable(tf.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = tf.nn.sigmoid(tf.matmul(X,w1)+b1)\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1,w2)+b2)\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2,w3)+b3)\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3,w4)+b4)\n",
    "\n",
    "Ylogits = tf.matmul(Y4,w5) + b5 ##because we need to do classification and calculate probability . \n",
    "###we don't care the probaility in hidden layers,cost function has two log\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define loss,reduce_mean:Computes the mean of elements across dimensions of a tensor.\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_true)) \n",
    "learning_rate = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "### index, argmax:Returns the index with the largest value across axes of a tensor. (deprecated arguments)\n",
    "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_true, 1))#####???????\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))## change the correct_pred into float32 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "##tf.session: A class for running TensorFlow operations.\n",
    "sess = tf.Session()\n",
    "batch_size = 200\n",
    "num_epochs = 100\n",
    "batch_count = int(len(x_train)/batch_size)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step number 1 loss is 2.28786 accuracy 0.24\n",
      "step number 2 loss is 2.2828226 accuracy 0.105\n",
      "step number 3 loss is 2.241151 accuracy 0.33\n",
      "step number 4 loss is 2.1680982 accuracy 0.5\n",
      "step number 5 loss is 2.0957606 accuracy 0.48\n",
      "step number 6 loss is 1.9536449 accuracy 0.55\n",
      "step number 7 loss is 1.8183322 accuracy 0.695\n",
      "step number 8 loss is 1.6952916 accuracy 0.655\n",
      "step number 9 loss is 1.5344843 accuracy 0.735\n",
      "step number 10 loss is 1.3407168 accuracy 0.76\n",
      "step number 11 loss is 1.2828332 accuracy 0.75\n",
      "step number 12 loss is 1.1992944 accuracy 0.76\n",
      "step number 13 loss is 1.0895442 accuracy 0.85\n",
      "step number 14 loss is 0.99698853 accuracy 0.84\n",
      "step number 15 loss is 0.8875805 accuracy 0.86\n",
      "step number 16 loss is 0.81996995 accuracy 0.905\n",
      "step number 17 loss is 0.7466749 accuracy 0.905\n",
      "step number 18 loss is 0.6693388 accuracy 0.915\n",
      "step number 19 loss is 0.61560255 accuracy 0.945\n",
      "step number 20 loss is 0.5712262 accuracy 0.975\n",
      "step number 21 loss is 0.55892044 accuracy 0.97\n",
      "step number 22 loss is 0.45627716 accuracy 0.985\n",
      "step number 23 loss is 0.42669237 accuracy 0.985\n",
      "step number 24 loss is 0.39853537 accuracy 1.0\n",
      "step number 25 loss is 0.3696604 accuracy 0.995\n",
      "step number 26 loss is 0.31433293 accuracy 0.995\n",
      "step number 27 loss is 0.29105365 accuracy 1.0\n",
      "step number 28 loss is 0.26513633 accuracy 1.0\n",
      "step number 29 loss is 0.25049484 accuracy 1.0\n",
      "step number 30 loss is 0.24119484 accuracy 1.0\n",
      "step number 31 loss is 0.21490099 accuracy 1.0\n",
      "step number 32 loss is 0.1833292 accuracy 1.0\n",
      "step number 33 loss is 0.1609449 accuracy 1.0\n",
      "step number 34 loss is 0.16029848 accuracy 1.0\n",
      "step number 35 loss is 0.1465023 accuracy 1.0\n",
      "step number 36 loss is 0.14617006 accuracy 1.0\n",
      "step number 37 loss is 0.13300475 accuracy 1.0\n",
      "step number 38 loss is 0.124029934 accuracy 1.0\n",
      "step number 39 loss is 0.113901235 accuracy 1.0\n",
      "step number 40 loss is 0.104674995 accuracy 1.0\n",
      "step number 41 loss is 0.10812435 accuracy 0.995\n",
      "step number 42 loss is 0.10242946 accuracy 1.0\n",
      "step number 43 loss is 0.094969615 accuracy 1.0\n",
      "step number 44 loss is 0.08484087 accuracy 1.0\n",
      "step number 45 loss is 0.09018638 accuracy 1.0\n",
      "step number 46 loss is 0.08403288 accuracy 1.0\n",
      "step number 47 loss is 0.07468894 accuracy 1.0\n",
      "step number 48 loss is 0.07241306 accuracy 1.0\n",
      "step number 49 loss is 0.072554 accuracy 1.0\n",
      "step number 50 loss is 0.06500151 accuracy 1.0\n",
      "step number 51 loss is 0.063533746 accuracy 1.0\n",
      "step number 52 loss is 0.05823093 accuracy 1.0\n",
      "step number 53 loss is 0.059377965 accuracy 1.0\n",
      "step number 54 loss is 0.05392665 accuracy 1.0\n",
      "step number 55 loss is 0.051609956 accuracy 1.0\n",
      "step number 56 loss is 0.054045152 accuracy 1.0\n",
      "step number 57 loss is 0.04914297 accuracy 1.0\n",
      "step number 58 loss is 0.048934717 accuracy 1.0\n",
      "step number 59 loss is 0.045963988 accuracy 1.0\n",
      "step number 60 loss is 0.04666877 accuracy 1.0\n",
      "step number 61 loss is 0.043460086 accuracy 1.0\n",
      "step number 62 loss is 0.041867122 accuracy 1.0\n",
      "step number 63 loss is 0.041438676 accuracy 1.0\n",
      "step number 64 loss is 0.040180854 accuracy 1.0\n",
      "step number 65 loss is 0.040410586 accuracy 1.0\n",
      "step number 66 loss is 0.035996094 accuracy 1.0\n",
      "step number 67 loss is 0.03753798 accuracy 1.0\n",
      "step number 68 loss is 0.03557834 accuracy 1.0\n",
      "step number 69 loss is 0.034496106 accuracy 1.0\n",
      "step number 70 loss is 0.032895736 accuracy 1.0\n",
      "step number 71 loss is 0.031542417 accuracy 1.0\n",
      "step number 72 loss is 0.030501962 accuracy 1.0\n",
      "step number 73 loss is 0.030942773 accuracy 1.0\n",
      "step number 74 loss is 0.03017748 accuracy 1.0\n",
      "step number 75 loss is 0.030365475 accuracy 1.0\n",
      "step number 76 loss is 0.027876921 accuracy 1.0\n",
      "step number 77 loss is 0.027025957 accuracy 1.0\n",
      "step number 78 loss is 0.026847042 accuracy 1.0\n",
      "step number 79 loss is 0.02584602 accuracy 1.0\n",
      "step number 80 loss is 0.025794208 accuracy 1.0\n",
      "step number 81 loss is 0.024840973 accuracy 1.0\n",
      "step number 82 loss is 0.02457788 accuracy 1.0\n",
      "step number 83 loss is 0.024096712 accuracy 1.0\n",
      "step number 84 loss is 0.02445558 accuracy 1.0\n",
      "step number 85 loss is 0.023533083 accuracy 1.0\n",
      "step number 86 loss is 0.023406656 accuracy 1.0\n",
      "step number 87 loss is 0.021304179 accuracy 1.0\n",
      "step number 88 loss is 0.021181285 accuracy 1.0\n",
      "step number 89 loss is 0.02047846 accuracy 1.0\n",
      "step number 90 loss is 0.020816512 accuracy 1.0\n",
      "step number 91 loss is 0.019632114 accuracy 1.0\n",
      "step number 92 loss is 0.019128012 accuracy 1.0\n",
      "step number 93 loss is 0.020167075 accuracy 1.0\n",
      "step number 94 loss is 0.01910877 accuracy 1.0\n",
      "step number 95 loss is 0.018761208 accuracy 1.0\n",
      "step number 96 loss is 0.018234262 accuracy 1.0\n",
      "step number 97 loss is 0.018230354 accuracy 1.0\n",
      "step number 98 loss is 0.017892925 accuracy 1.0\n",
      "step number 99 loss is 0.017421575 accuracy 1.0\n",
      "step number 100 loss is 0.016285053 accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "for step in range(1,num_epochs+1):\n",
    "    for i in range(batch_count):\n",
    "        batch_x,batch_y = next_batch(batch_size,x_train,onehot_train)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y_true: batch_y})\n",
    "    loss,acc = sess.run([loss_op,accuracy],feed_dict = {X: batch_x, Y_true:batch_y})\n",
    "    print('step number',step,'loss is' ,loss,\"accuracy\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### try the test data\n",
    "onehot_test = enc.transform(np.expand_dims(y_test,axis =1)).toarray()\n",
    "onehot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20703858, 0.9577778]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([loss_op,accuracy],feed_dict = {X: x_test, Y_true: onehot_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01699571, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([loss_op,accuracy],feed_dict = {X: x_train, Y_true: onehot_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
